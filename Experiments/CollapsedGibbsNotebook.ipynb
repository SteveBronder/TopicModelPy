{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.special import gammaln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314991, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "DIR = r'data_folder/wordcounts'\n",
    "allfiles = glob.glob(os.path.join(DIR,\"*.CSV\"))\n",
    "\n",
    "p = .5\n",
    "rand_sample = [ allfiles[i] for i in sorted(random.sample(xrange(len(allfiles)), int(p * len(allfiles)))) ]\n",
    "rand_sample\n",
    "    \n",
    "np_array_list = []\n",
    "for file_ in rand_sample:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    df['source'] = file_\n",
    "    np_array_list.append(df.as_matrix())\n",
    "    \n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "big_frame = pd.DataFrame(comb_np_array)\n",
    "big_frame.columns = ['words','count','source']\n",
    "big_test = big_frame.head(n=10000)\n",
    "big_test = big_test.pivot(index = 'source',columns = 'words', values = 'count')\n",
    "big_test = big_test.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are some nonsense words in here, can we use some sort of dictionary to sweep them out?\n",
    "''' \n",
    "My best guess as to why this is happening is:\n",
    "1. As JSTOR parses the data things like equations and tables become jibberish.\n",
    "2. Maybe we are using the wrong character format? Maybe it's unicode?\n",
    "3. Aliens\n",
    "'''\n",
    "big_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>words</th>\n",
       "      <th>nan</th>\n",
       "      <th>aac</th>\n",
       "      <th>aacm</th>\n",
       "      <th>aalen</th>\n",
       "      <th>aam</th>\n",
       "      <th>aamse</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aban</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>...</th>\n",
       "      <th>zu</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zwet</th>\n",
       "      <th>zx</th>\n",
       "      <th>zygmund</th>\n",
       "      <th>zyskind</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276708.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276742.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276818.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276856.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276867.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "words                                               NaN  aac  aacm  aalen  \\\n",
       "source                                                                      \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0    0     0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0    0     0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0    0     0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0    0     0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0    0     0      0   \n",
       "\n",
       "words                                               aam  aamse  aaron  aban  \\\n",
       "source                                                                        \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0      0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0      0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0      0     0   \n",
       "\n",
       "words                                               abandon  abandoned ...  \\\n",
       "source                                                                 ...   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...        0          0 ...   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...        0          0 ...   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0          0 ...   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0          0 ...   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0          0 ...   \n",
       "\n",
       "words                                               zu  zucker  zurich  zv  \\\n",
       "source                                                                       \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...   0       0       0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...   0       0       0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0       0       0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0       0       0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0       0       0   0   \n",
       "\n",
       "words                                               zw  zwet  zx  zygmund  \\\n",
       "source                                                                      \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...   0     0   0        0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...   0     0   0        0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0     0   0        0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0     0   0        0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0     0   0        0   \n",
       "\n",
       "words                                               zyskind  zz  \n",
       "source                                                           \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0   0  \n",
       "\n",
       "[5 rows x 10124 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could do a couple of shady things like this to help remove those\n",
    "big_frame = big_frame.loc[:, (big_frame.sum(axis = 0) > 2)]\n",
    "big_frame = big_frame.loc[:, (big_frame.sum(axis = 0) < 20)]\n",
    "big_frame.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1057.724457\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_multinomial_beta(alpha):\n",
    "    '''\n",
    "    Function to take the logarithm of the multinomial beta function\n",
    "    '''\n",
    "    return np.sum(gammaln(alpha)) - gammaln(np.sum(alpha))\n",
    "\n",
    "testAlpha = pd.DataFrame(random.sample(range(1,100),10),index = xrange(10), columns = xrange(1))\n",
    "log_multinomial_beta(testAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10124)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_frame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run this, but not the one that looks the same below it\n",
    "M, N = big_frame.shape\n",
    "\n",
    "# Dimensions\n",
    "# M: Number of documents\n",
    "# N: Number of words\n",
    "# ntopics: Number of topics\n",
    "\n",
    "alpha = .3\n",
    "beta = .3\n",
    "burn_in = 10\n",
    "max_iter = 100\n",
    "ntopics = 6\n",
    "\n",
    "NWZ = np.zeros((N,ntopics), dtype=np.float64) + beta\n",
    "NZM = np.zeros((ntopics,M), dtype = np.float64) + alpha\n",
    "NZ = NWZ.sum(axis=0)\n",
    "Z = np.zeros((M,N), dtype = np.float64)\n",
    "Phi = np.zeros((N,ntopics), dtype = np.float64)\n",
    "Theta = np.zeros((N,ntopics), dtype = np.float64)\n",
    "topicdraw = np.ones((1,ntopics), dtype = np.float64) / ntopics\n",
    "read_out_Phi = np.zeros((N,ntopics), dtype = np.float64)\n",
    "read_out_Theta = np.zeros((ntopics,M))\n",
    "read_out_sampling_num = 0\n",
    "logPw_z = np.zeros(max_iter, dtype = np.float64)\n",
    "betaVec = np.ones(ntopics, dtype = np.float64) * beta\n",
    "sampling_lag = 10\n",
    "\n",
    "Z = np.where(np.random.multinomial(1,[1./ntopics]*ntopics,size = M*N )==1)[1]\n",
    "Z_index = Z.reshape(M*N)\n",
    "Z = Z.reshape(M,N)\n",
    "big_frame_index = big_frame.stack()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I keep getting memory errors, so had to use a loop to iterate\n",
    "# is there some way to get around this?\n",
    "for m in xrange(M):\n",
    "    NZM[Z_index,m] += 1\n",
    "    \n",
    "NWZ[big_frame_index,Z_index] +=1\n",
    "NZ[Z_index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-df7e379e6c48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNZM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mZ_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mNWZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbig_frame_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mNZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mZ_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NZM[Z_index,:] += 1    \n",
    "NWZ[big_frame_index,Z_index] +=1\n",
    "NZ[Z_index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# This is the old one, do not run this\n",
    "M, N = big_frame.shape\n",
    "\n",
    "# Dimensions\n",
    "# M: Number of documents\n",
    "# N: Number of words\n",
    "# ntopics: Number of topics\n",
    "\n",
    "# For now, try to set not small amount for alpha and beta\n",
    "# else negative numbers can pop up elsewhere due to rounding error\n",
    "alpha = .3\n",
    "beta = .3\n",
    "burn_in = 10\n",
    "max_iter = 100\n",
    "ntopics = 6\n",
    "\n",
    "NWZ = np.zeros((m,ntopics), dtype=np.float64) + beta\n",
    "NZM = np.zeros((ntopics,M), dtype = np.float64) + alpha\n",
    "NZ = NWZ.sum(axis=0)\n",
    "Z = np.zeros((M,N), dtype = np.float64)\n",
    "Phi = np.zeros((M,N), dtype = np.float64)\n",
    "Theta = np.zeros((N,ntopics), dtype = np.float64)\n",
    "topicdraw = np.ones((1,ntopics), dtype = np.float64) / ntopics\n",
    "read_out_Phi = np.zeros((N,ntopics), dtype = np.float64)\n",
    "read_out_Theta = np.zeros((ntopics,M))\n",
    "read_out_sampling_num = 0\n",
    "logPw_z = np.zeros(max_iter, dtype = np.float64)\n",
    "betaVec = np.ones(ntopics, dtype = np.float64) * beta\n",
    "sampling_lag = 10\n",
    "\n",
    "\n",
    "Z = np.where(np.random.multinomial(1,[1./ntopics]*ntopics,size = M*N )==1)[1]\n",
    "Z = pd.DataFrame(Z.reshape(M,N))\n",
    "\n",
    "# Draw the initial starting points\n",
    "for m in xrange(M):\n",
    "    for n in xrange(N):\n",
    "        NZM[Z[m,n],m] = NZM[Z[m,n],m] + 1\n",
    "        NWZ[big_frame[m,n],Z[m,n]] = NWZ[big_frame[m,n],Z[m,n]] + 1\n",
    "        NZ[Z[m,n]] = NZ[Z[m,n]] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying to vectorize this\n",
    "\n",
    "for iteration in xrange(maxa_iter):\n",
    "    # I think we need to do it over each document\n",
    "    for m in xrange(M):\n",
    "        NWZ[Z_index,:] -= 1\n",
    "        NWZ[big_frame_index,Z_index] -=1\n",
    "        NZ[Z_index] -= 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.zeros(ntopics, dtype = np.float64)\n",
    "for k in xrange(ntopics):\n",
    "    p[k] = NWZ[big_frame.iloc[m,n],k]/NZ[k] * NZM[k,m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 3, ..., 4, 0, 0],\n",
       "       [0, 4, 0, ..., 4, 2, 0],\n",
       "       [0, 3, 1, ..., 4, 4, 1],\n",
       "       ..., \n",
       "       [2, 3, 0, ..., 0, 1, 2],\n",
       "       [4, 3, 4, ..., 3, 2, 5],\n",
       "       [0, 3, 3, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z.setflags(write=True)\n",
    "\n",
    "for iteration in xrange(max_iter):\n",
    "        for m in xrange(M):\n",
    "            for n in xrange(N):\n",
    "                #NZM[Z[m,n],m] -= 1\n",
    "                #NWZ[big_frame.iloc[m,n],Z[m,n]] -= 1\n",
    "                #NZ[Z[m,n]] -= 1\n",
    "                p = np.zeros(ntopics, dtype = np.float64)\n",
    "                for k in xrange(ntopics):\n",
    "                    p[k] = NWZ[big_frame.iloc[m,n],k]/NZ[k] * NZM[k,m]\n",
    "                \n",
    "                p = p / np.sum(p)\n",
    "                Z[m,n] = np.where(np.random.multinomial(1,p,size = 1 ) == 1)[1]\n",
    "                NZM[Z[m,n],m] += 1\n",
    "                NWZ[big_frame.iloc[m,n],Z[m,n]] += 1\n",
    "                NZ[Z[m,n]] += 1\n",
    "        \n",
    "        \n",
    "        for ZZ in xrange(ntopics):\n",
    "            logPw_z[iteration] += log_multinomial_beta(NWZ[:,ZZ]) - log_multinomial_beta(betaVec)\n",
    "        \n",
    "        if iteration % sampling_lag == 0 or iteration % sampling_lag == 1:\n",
    "            if iteration >= burn_in:\n",
    "                read_out_sampling_num = read_out_sampling_num + 1\n",
    "                for k in xrange(ntopics):\n",
    "                    read_out_Phi[:,k] += NWZ[:,k] / NZ[k]\n",
    "                \n",
    "                for m in xrange(M):\n",
    "                    read_out_Theta[:,m] +=  NZM[:,m]/sum(NZM[:,m])\n",
    "                \n",
    "Phi = read_out_Phi / read_out_sampling_num\n",
    "Theta = read_out_Theta / read_out_sampling_num\n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10124,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_out_Phi[:,k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NWZ[:,k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(logPw_z.transpose())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
