{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gibbssampler(matrix,nzw,nzm,nz,nm,max_iter,p_z,topics,topics2,[ntopics,m,n])\n",
      "\n",
      "Wrapper for ``gibbssampler``.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "matrix : input rank-2 array('i') with bounds (m,n)\n",
      "nzw : input rank-2 array('i') with bounds (n,ntopics)\n",
      "nzm : input rank-2 array('i') with bounds (ntopics,m)\n",
      "nz : input rank-1 array('i') with bounds (ntopics)\n",
      "nm : input rank-1 array('i') with bounds (m)\n",
      "max_iter : input int\n",
      "p_z : input rank-1 array('f') with bounds (ntopics)\n",
      "topics : input rank-2 array('i') with bounds (m,n)\n",
      "topics2 : input rank-2 array('i') with bounds (m,n)\n",
      "\n",
      "Other Parameters\n",
      "----------------\n",
      "ntopics : input int, optional\n",
      "    Default: shape(nzw,1)\n",
      "m : input int, optional\n",
      "    Default: shape(matrix,0)\n",
      "n : input int, optional\n",
      "    Default: shape(matrix,1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./fortran')\n",
    "import gibbsSampler\n",
    "print gibbsSampler.gibbs_sampler.gibbssampler.__doc__\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.special import gammaln\n",
    "import scipy.misc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "random.seed(1234)\n",
    "#\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.special import gammaln\n",
    "\n",
    "def index_sample(p):\n",
    "    \"\"\"\n",
    "    Desc: Samples from n topics distributed multinomially and returns topic number\n",
    "    input: p - A one dimensional array of float64 type that contains the probability for each topic\n",
    "    output: an Integer specifying which topic was chosen from a multinomial distribution\n",
    "    \"\"\"\n",
    "    r = random.random()\n",
    "    for i in range(len(p)):\n",
    "        r = r - p[i]\n",
    "        if r < 0:\n",
    "            return i\n",
    "    return len(p) - 1\n",
    "\n",
    "def word_indices(vec):\n",
    "    \"\"\"\n",
    "    Desc: Take a vector of word counts from a document and create a generator for word indices\n",
    "    input: A vector from a Document Term Frequency matrix for one document.\n",
    "    output: A generator object to store the word indices when called\n",
    "    \"\"\"\n",
    "    for idx in vec.nonzero()[0]:\n",
    "        for i in xrange(int(vec[idx])):\n",
    "            yield idx\n",
    "\n",
    "def log_multi_beta(alpha, K = None):\n",
    "    \"\"\"\n",
    "    Desc: Compute the logarithm of the multinomial beta function\n",
    "    input: alpha - A vector with type float64 or a scaler of float64\n",
    "           K - An integer that, if alpha is a scalar, multiplies the log by K\n",
    "    output: a float64 with value of the logarithm of the multinomial beta\n",
    "    \"\"\"\n",
    "\n",
    "    if K is None:\n",
    "        return np.sum(gammaln(alpha) - gammaln(np.sum(alpha)))\n",
    "    else:\n",
    "        return K * gammaln(alpha) - gammaln(K * alpha)\n",
    "\n",
    "class LdaSampler(object):\n",
    "\n",
    "    def __init__(self,  data, ntopics, alpha = .1, beta = .1):\n",
    "        \"\"\"\n",
    "        Desc: Initialize values for our class object\n",
    "        alpha: a float scalar\n",
    "        beta: a float scalar\n",
    "        ntopics: an integer for the number of topics\n",
    "        \"\"\"\n",
    "        if not isinstance(alpha, float):\n",
    "            raise Exception(\" Initial value for alpha must be a floating point number (.3)\")\n",
    "\n",
    "        if not isinstance(beta, float):\n",
    "            raise Exception(\" Initial value for beta must be a floating point number (.3)\")\n",
    "\n",
    "        if not isinstance(ntopics, int):\n",
    "            raise Exception(\" The number of topics must be an integer\")\n",
    "\n",
    "        self.matrix = data\n",
    "        self.ntopics = ntopics\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self._initialize()\n",
    "    def _initialize(self):\n",
    "        \"\"\"\n",
    "        Initialize:\n",
    "        NZM: size(#Docs X #Topics) numpy array with type float 64\n",
    "            The number of times document M and topic Z interact\n",
    "\n",
    "        NZW: size(#Topics X #Words) numpy array with type float64\n",
    "            The number of times topic Z and word W interact\n",
    "\n",
    "        NM:  size(#Docs) numpy array with type float64\n",
    "            Sum of documents occurances by topic and word\n",
    "\n",
    "        NZ:  size(#Topics) numpy array with type float64\n",
    "            Sum of Topic occurences by word and document\n",
    "\n",
    "        Topics: size(?) An empty set\n",
    "           Will come back to this\n",
    "        \"\"\"\n",
    "        ndocs, vsize = self.matrix.shape\n",
    "\n",
    "        self.NZM = np.zeros((ndocs, self.ntopics))\n",
    "        self.NZW = np.zeros((self.ntopics, vsize))\n",
    "        self.NM  = np.zeros(ndocs)\n",
    "        self.NZ  = np.zeros(self.ntopics)\n",
    "        self.topics = np.zeros((ndocs,vsize))\n",
    "        self.logL = []\n",
    "        \n",
    "        for m in xrange(ndocs):\n",
    "            # Iterates over i, doc_length - 1, and w, the size of unique_words - 1\n",
    "            for n in xrange(vsize):\n",
    "                if self.matrix[m,n] == 0:\n",
    "                    continue\n",
    "                for w in xrange(self.matrix[m,n]):\n",
    "                # Initialize a random topic for each word\n",
    "                    z = np.random.randint(self.ntopics)\n",
    "                    self.topics[m,n] = z\n",
    "                    self.NZM[m,z] += 1\n",
    "                # Why is NM being +1'd for each i,w?\n",
    "                    self.NM[m] += 1\n",
    "                    self.NZW[z,n] += 1\n",
    "                    self.NZ[z] += 1\n",
    "                # Keep document, iterator for word, word index, and assignment\n",
    "                #self.topics.append([i,w,z])\n",
    "        \n",
    "        #self.topics = np.vstack(self.topics)\n",
    "    def _conditional_distribution(self, m, n):\n",
    "        \"\"\"\n",
    "        Desc: Compute the conditional distribution of words in document and topic\n",
    "        Input: m: An integer representing the column index of the document\n",
    "               w: The generator object from word_indices\n",
    "\n",
    "        Output: p_z: An array size(w X 1) containing probabilities for topics of word\n",
    "        \n",
    "        The formula is:\n",
    "        ((n_{k,-i}^(t) + \\beta_t)/\\sum_{t=1}^V(n_{k,-i}^(t) + \\beta_t)) *\n",
    "        ((n_{m,-i}^(t) + \\alpha_k)/(\\sum_{k=1}^K(n_m^k + \\alpha_k) - 1))\n",
    "        \"\"\"\n",
    "        vsize = self.NZW.shape[1]\n",
    "        left = (np.delete(self.NZW,n,axis=1) + self.beta) / (self.NZ + self.beta * vsize)[:,None]\n",
    "        print \"left\"\n",
    "        print left\n",
    "        # Changed NZM _ one top to matrix to be concurrent with equation 79.\n",
    "        # Also, on bottom changed NM[m] to NZM[m,:] to sum over interaction of topic and doc\n",
    "        right = (np.delete(self.matrix[m,:],n) + self.alpha) / sum(self.NZM[m,:] + self.alpha * self.ntopics)\n",
    "        print \"right\"\n",
    "        print right\n",
    "        # Left and Right are 4x3, so do 4x3 * 3x4 for 4x4 Z transition matrix\n",
    "        \n",
    "        p_z = np.dot(left , right.transpose())\n",
    "        print \"p_z before abs\"\n",
    "        print p_z\n",
    "        p_z = abs(p_z)\n",
    "        print \"p_z after abs\"\n",
    "        print p_z\n",
    "        p_z /= np.sum(p_z)\n",
    "        print p_z\n",
    "        return p_z\n",
    "\n",
    "    def loglikelihood(self):\n",
    "        \"\"\"\n",
    "        Desc: Compute the log likelihood that the model generated the data\n",
    "        Input: self references\n",
    "        Output: lik: float of the log likelihood\n",
    "        \"\"\"\n",
    "        # Why are these being repeated here?\n",
    "        vsize = self.NZW.shape[1]\n",
    "        ndocs = self.NZM.shape[0]\n",
    "        lik = 0\n",
    "\n",
    "        for z in xrange(self.ntopics):\n",
    "            lik += log_multi_beta(self.NZW[z,:] + self.beta)\n",
    "            lik -= log_multi_beta(self.beta, vsize)\n",
    "\n",
    "        for m in xrange(ndocs):\n",
    "            lik += log_multi_beta(self.NZM[m,:] + self.alpha)\n",
    "            lik -= log_multi_beta(self.alpha, self.ntopics)\n",
    "\n",
    "        return lik\n",
    "\n",
    "    def phi_theta(self):\n",
    "        \"\"\"\n",
    "        Desc: Compute phi and theta, our topic by word probs and document by topic probs\n",
    "        Input: Self references\n",
    "        Output: Two arrays, holding\n",
    "            [0] phi: Probability of topic by word\n",
    "            [1] theta: Probability of document by topic\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        num_phi = self.NZW + self.beta\n",
    "        num_phi /= np.sum(num_phi, axis = 0)[np.newaxis,:]\n",
    "\n",
    "        num_theta = self.NZM + self.alpha\n",
    "        num_theta /= np.sum(num_theta,axis = 0)[ np.newaxis,:]\n",
    "\n",
    "        return num_phi, num_theta\n",
    "\n",
    "\n",
    "    def run(self, maxiter = 30, burnin= 0):\n",
    "        \"\"\"\n",
    "        Desc: Perform Gibbs sampling for maxiter iterations\n",
    "\n",
    "        Input: matrix - An array that is a Document Term Frequency Matrix\n",
    "               maxiter - An integer with the number of iterations\n",
    "               Burnin - TBA: An integer of the number of burnins\n",
    "\n",
    "        Output: phi_theta() Two arrays, holding\n",
    "        [0] Probability of topic by word\n",
    "        [1] Probability of document by topic\n",
    "        \"\"\"\n",
    "\n",
    "        n_docs, vsize = self.matrix.shape\n",
    "        topics2 = self.topics\n",
    "\n",
    "\n",
    "        for iteration in xrange(maxiter + 2):\n",
    "            # Idea: After each iteration we now want to\n",
    "            # make assignments relative to the newly generated topics\n",
    "            if iteration > 1:\n",
    "                self.topics = topics2\n",
    "            for m in xrange(n_docs):\n",
    "                for n in xrange(vsize):\n",
    "                    if self.matrix[m,n] == 0:\n",
    "                        continue\n",
    "                    for w in xrange(self.matrix[m,n]):\n",
    "                        \n",
    "                        z = self.topics[m,n]\n",
    "                    \n",
    "                        self.NZM[m,z] -= 1\n",
    "                        self.NM[m] -= 1\n",
    "                        self.NZW[z,n] -= 1\n",
    "                        self.NZ[z] -= 1\n",
    "\n",
    "                        p_z = self._conditional_distribution(m,n)\n",
    "                        # Choosing a random topic row\n",
    "                        ind_z = np.random.randint(self.ntopics)\n",
    "                    \n",
    "                        # Sampling random topic\n",
    "                        z = index_sample(p_z)\n",
    "                        \n",
    "                        #Self.topics needs to change after we iterate over this word\n",
    "                        # Otherwise at each iteration we subtract one from that space w*n times\n",
    "                        # giving us a negative number\n",
    "                        topics2[m,n] = z\n",
    "\n",
    "                        self.NZM[m,z] += 1\n",
    "                        self.NM[m] += 1\n",
    "                        self.NZW[z,n] += 1\n",
    "                        self.NZ[z] += 1\n",
    "\n",
    "            if iteration > burnin:\n",
    "                yield self.phi_theta()\n",
    "\n",
    "                \n",
    "    def runfort(self, maxiter = 30, burnin= 0):\n",
    "        \"\"\"\n",
    "        Desc: Perform Gibbs sampling for maxiter iterations\n",
    "\n",
    "        Input: matrix - An array that is a Document Term Frequency Matrix\n",
    "               maxiter - An integer with the number of iterations\n",
    "               Burnin - TBA: An integer of the number of burnins\n",
    "\n",
    "        Output: phi_theta() Two arrays, holding\n",
    "        [0] Probability of topic by word\n",
    "        [1] Probability of document by topic\n",
    "        \"\"\"\n",
    "\n",
    "        M,N = self.matrix.shape\n",
    "\n",
    "        p_z = np.zeros(self.ntopics)\n",
    "        p_z += 1./self.ntopics\n",
    "        gibbsSampler.gibbs_sampler.gibbssampler(matrix = self.matrix, nzw = self.NZW.transpose(),\n",
    "                                                nzm = self.NZM.transpose(),\n",
    "                                                nz = self.NZ,\n",
    "                                                nm = self.NM,\n",
    "                                                max_iter = maxiter,\n",
    "                                                p_z = p_z)\n",
    "\n",
    "        #if iteration > burnin:\n",
    "        return self.phi_theta()\n",
    "                \n",
    "                \n",
    "\n",
    "    def prn(self,x = None):\n",
    "        print x\n",
    "\n",
    "    # For some reason this returns (maxiter - burnin) - 2 iterations?\n",
    "    def update(self, maxiter = 20, burnin = 0):\n",
    "        \"\"\"\n",
    "        Desc: Runs gibbs sampler for maxiter iterations\n",
    "            Input: maxiter - integer specifying maximum number of iterations\n",
    "                   burnin  - integer specifying number of iterations to burn through.\n",
    "                                should be set to zero after initial burnin\n",
    "            Output: phi_theta() Two arrays, holding\n",
    "                [0] Probability of topic by word\n",
    "                [1] Probability of document by topic\n",
    "        \"\"\"\n",
    "        \n",
    "        for iteration, phi_theta in enumerate(self.run( maxiter, burnin)):\n",
    "            self.prn(iteration)\n",
    "            self.prn(self.loglikelihood())\n",
    "            self.logL.append(self.loglikelihood())\n",
    "        return self.phi_theta(), self.logL\n",
    "\n",
    "    def __call__(self):\n",
    "        self.NZM = self.NZM\n",
    "        self.NM = self.NM\n",
    "        self.NZW = self.NZW\n",
    "        self.NZ = self.NZ\n",
    "        self.logL = self.logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.array([[1,2,3,4],[1,2,3,4]])\n",
    "print arr\n",
    "arr2 = np.delete(arr, 1,axis=1)\n",
    "print arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "DIR = r'data_folder/wordcounts'\n",
    "allfiles = glob.glob(os.path.join(DIR,\"*.CSV\"))\n",
    "p=.5\n",
    "# sample files for train\n",
    "gen_sample = np.array(sorted(random.sample(xrange(len(allfiles)), int(p * len(allfiles)))))\n",
    "rand_sample = [ allfiles[i] for i in gen_sample ]\n",
    "#\n",
    "# take rest for test\n",
    "rand_sample2 = []\n",
    "for i in xrange(len(allfiles)):\n",
    "    if i not in gen_sample:\n",
    "        rand_sample2.append(allfiles[i])\n",
    "#\n",
    "# train data\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in rand_sample:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    df['source'] = file_\n",
    "    np_array_list.append(df.as_matrix())\n",
    "#\n",
    "# test data\n",
    "np_array_list_test = []\n",
    "for file_ in rand_sample2:\n",
    "    df = pd.read_csv(file_, index_col = None, header = 0)\n",
    "    df['source'] = file_\n",
    "    np_array_list_test.append(df.as_matrix())\n",
    "    \n",
    "#\n",
    "# train data frame\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "train_frame = pd.DataFrame(comb_np_array)\n",
    "train_frame.columns = ['words','count','source']\n",
    "subless = (train_frame['words'].str.len() > 2)\n",
    "submore = (train_frame['words'].str.len() < 20)\n",
    "train_frame = train_frame.loc[subless]\n",
    "train_frame = train_frame.loc[submore]\n",
    "train_frame = train_frame.fillna(value = 0)\n",
    "train_frame = train_frame.pivot(index = 'source',columns = 'words', values = 'count')\n",
    "train_frame = train_frame.fillna(value = 0)\n",
    "train_frame = train_frame.loc[:, (train_frame.sum(axis = 0) > 5)]\n",
    "#\n",
    "\n",
    "# test data frame\n",
    "comb_np_array_test = np.vstack(np_array_list_test)\n",
    "test_frame = pd.DataFrame(comb_np_array_test)\n",
    "test_frame.columns = ['words','count','source']\n",
    "test_frame = test_frame.fillna(value=0)\n",
    "test_frame = test_frame.pivot(index = 'source', columns = 'words', values = 'count')\n",
    "test_frame = test_frame.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "integer argument expected, got float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ceefd42d096d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msampler1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntopics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msampler1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mburnin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b1ed5a4af3da>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, ntopics, alpha, beta)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \"\"\"\n",
      "\u001b[1;32m<ipython-input-1-b1ed5a4af3da>\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Initialize a random topic for each word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mntopics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: integer argument expected, got float"
     ]
    }
   ],
   "source": [
    "sampler1 = LdaSampler(data = test_frame.values, ntopics = 4, alpha = .1, beta = .1)\n",
    "sampler1.update( maxiter =1, burnin = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_frame = np.array([[1,0,4,2],[2,4,0,5]])\n",
    "sampler = LdaSampler(data = testing_frame, ntopics = 4, alpha = .1, beta = .1)\n",
    "p_z = np.zeros(4) + .25\n",
    "topics2 = sampler.topics\n",
    "M,N = testing_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testtt = np.array([[ 1.125,       1.125 ,      0.32142857 , 0.32142857],\n",
    " [ 1.30357143 , 1.30357143 , 0.37244898  ,0.37244898],\n",
    " [ 8.44642857,  8.44642857,  2.41326531 , 2.41326531],\n",
    " [ 5.03125,     5.03125 ,    1.4375 ,     1.4375    ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.28378378  0.14864865  0.41891892]\n",
      " [ 0.78571429  0.07142857  0.07142857]]\n",
      "[ 0.01315789  0.53947368  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.22882401  0.42298762  0.19967994  0.06860902]\n",
      "p_z after abs\n",
      "[ 0.22882401  0.42298762  0.19967994  0.06860902]\n",
      "[ 0.24869456  0.45971888  0.21701969  0.07456687]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02941176  0.02941176  0.32352941]\n",
      " [ 0.171875    0.328125    0.484375  ]\n",
      " [ 0.45833333  0.45833333  0.04166667]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "[ 0.32071608  0.18735544  0.32481207  0.16711642]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02941176  0.02941176  0.32352941]\n",
      " [ 0.171875    0.328125    0.484375  ]\n",
      " [ 0.45833333  0.45833333  0.04166667]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "[ 0.32071608  0.18735544  0.32481207  0.16711642]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02941176  0.02941176  0.32352941]\n",
      " [ 0.171875    0.328125    0.484375  ]\n",
      " [ 0.45833333  0.45833333  0.04166667]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "[ 0.32071608  0.18735544  0.32481207  0.16711642]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02941176  0.02941176  0.32352941]\n",
      " [ 0.171875    0.328125    0.484375  ]\n",
      " [ 0.45833333  0.45833333  0.04166667]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.09404025  0.16303454  0.08388158]\n",
      "[ 0.32071608  0.18735544  0.32481207  0.16711642]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02941176  0.02941176  0.61764706]\n",
      " [ 0.2037037   0.38888889  0.01851852]\n",
      " [ 0.32352941  0.32352941  0.32352941]]\n",
      "[ 0.14473684  0.01315789  0.53947368]\n",
      "p_z before abs\n",
      "[ 0.1198602   0.3378483   0.04459064  0.2256192 ]\n",
      "p_z after abs\n",
      "[ 0.1198602   0.3378483   0.04459064  0.2256192 ]\n",
      "[ 0.1646616   0.4641294   0.06125776  0.30995125]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02941176  0.02941176  0.61764706]\n",
      " [ 0.2037037   0.38888889  0.01851852]\n",
      " [ 0.32352941  0.32352941  0.32352941]]\n",
      "[ 0.14473684  0.01315789  0.53947368]\n",
      "p_z before abs\n",
      "[ 0.1198602   0.3378483   0.04459064  0.2256192 ]\n",
      "p_z after abs\n",
      "[ 0.1198602   0.3378483   0.04459064  0.2256192 ]\n",
      "[ 0.1646616   0.4641294   0.06125776  0.30995125]\n",
      "[[ 0.2037037   0.2037037   0.57407407]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.015625    0.484375  ]\n",
      " [ 0.32352941  0.32352941  0.02941176]]\n",
      "[ 0.35344828  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.32614943  0.15796146  0.32906789  0.13007099]\n",
      "p_z after abs\n",
      "[ 0.32614943  0.15796146  0.32906789  0.13007099]\n",
      "[ 0.34577207  0.16746515  0.34886612  0.13789666]\n",
      "[[ 0.2037037   0.2037037   0.57407407]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.015625    0.484375  ]\n",
      " [ 0.32352941  0.32352941  0.02941176]]\n",
      "[ 0.35344828  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.32614943  0.15796146  0.32906789  0.13007099]\n",
      "p_z after abs\n",
      "[ 0.32614943  0.15796146  0.32906789  0.13007099]\n",
      "[ 0.34577207  0.16746515  0.34886612  0.13789666]\n",
      "[[ 0.01851852  0.2037037   0.57407407]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.015625    0.484375  ]\n",
      " [ 0.32352941  0.32352941  0.02941176]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "p_z after abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "[ 0.34008262  0.20192134  0.35988168  0.09811435]\n",
      "[[ 0.01851852  0.2037037   0.57407407]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.015625    0.484375  ]\n",
      " [ 0.32352941  0.32352941  0.02941176]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "p_z after abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "[ 0.34008262  0.20192134  0.35988168  0.09811435]\n",
      "[[ 0.01851852  0.2037037   0.57407407]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.015625    0.484375  ]\n",
      " [ 0.32352941  0.32352941  0.02941176]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "p_z after abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "[ 0.34008262  0.20192134  0.35988168  0.09811435]\n",
      "[[ 0.01851852  0.2037037   0.57407407]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.015625    0.484375  ]\n",
      " [ 0.32352941  0.32352941  0.02941176]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "p_z after abs\n",
      "[ 0.25750319  0.15289047  0.27249461  0.07429006]\n",
      "[ 0.34008262  0.20192134  0.35988168  0.09811435]\n",
      "[[ 0.01851852  0.2037037   0.2037037 ]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.015625  ]\n",
      " [ 0.32352941  0.32352941  0.32352941]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "p_z after abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "[ 0.15480195  0.25095222  0.24148743  0.3527584 ]\n",
      "[[ 0.01851852  0.2037037   0.2037037 ]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.015625  ]\n",
      " [ 0.32352941  0.32352941  0.32352941]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "p_z after abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "[ 0.15480195  0.25095222  0.24148743  0.3527584 ]\n",
      "[[ 0.01851852  0.2037037   0.2037037 ]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.015625  ]\n",
      " [ 0.32352941  0.32352941  0.32352941]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "p_z after abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "[ 0.15480195  0.25095222  0.24148743  0.3527584 ]\n",
      "[[ 0.01851852  0.2037037   0.2037037 ]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.015625  ]\n",
      " [ 0.32352941  0.32352941  0.32352941]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "p_z after abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "[ 0.15480195  0.25095222  0.24148743  0.3527584 ]\n",
      "[[ 0.01851852  0.2037037   0.2037037 ]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.015625  ]\n",
      " [ 0.32352941  0.32352941  0.32352941]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "p_z after abs\n",
      "[ 0.07710728  0.125       0.12028556  0.17570994]\n",
      "[ 0.15480195  0.25095222  0.24148743  0.3527584 ]\n",
      "[[ 0.171875    0.171875    0.640625  ]\n",
      " [ 0.32352941  0.61764706  0.02941176]\n",
      " [ 0.171875    0.015625    0.484375  ]\n",
      " [ 0.45833333  0.45833333  0.04166667]]\n",
      "[ 0.01315789  0.53947368  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.27199836  0.34558824  0.14453125  0.26480263]\n",
      "p_z after abs\n",
      "[ 0.27199836  0.34558824  0.14453125  0.26480263]\n",
      "[ 0.26486798  0.33652872  0.1407424   0.25786089]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.32352941  0.02941176]\n",
      " [ 0.328125    0.171875    0.484375  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "p_z after abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "[ 0.42320056  0.03988579  0.44004814  0.0968655 ]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.32352941  0.02941176]\n",
      " [ 0.328125    0.171875    0.484375  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "p_z after abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "[ 0.42320056  0.03988579  0.44004814  0.0968655 ]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.32352941  0.02941176]\n",
      " [ 0.328125    0.171875    0.484375  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "p_z after abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "[ 0.42320056  0.03988579  0.44004814  0.0968655 ]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.32352941  0.02941176]\n",
      " [ 0.328125    0.171875    0.484375  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "p_z after abs\n",
      "[ 0.17656472  0.01664087  0.18359375  0.04041353]\n",
      "[ 0.42320056  0.03988579  0.44004814  0.0968655 ]\n",
      "[[ 0.14864865  0.14864865  0.14864865]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.14473684  0.01315789  0.53947368]\n",
      "p_z before abs\n",
      "[ 0.10366287  0.34171827  0.14247533  0.05921053]\n",
      "p_z after abs\n",
      "[ 0.10366287  0.34171827  0.14247533  0.05921053]\n",
      "[ 0.16020424  0.52810338  0.22018636  0.09150602]\n",
      "[[ 0.14864865  0.14864865  0.14864865]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.14473684  0.01315789  0.53947368]\n",
      "p_z before abs\n",
      "[ 0.10366287  0.34171827  0.14247533  0.05921053]\n",
      "p_z after abs\n",
      "[ 0.10366287  0.34171827  0.14247533  0.05921053]\n",
      "[ 0.16020424  0.52810338  0.22018636  0.09150602]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.25        0.47727273  0.25      ]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.78571429  0.07142857  0.07142857]]\n",
      "[ 0.35344828  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.29741379  0.20239028  0.2447318   0.30972906]\n",
      "p_z after abs\n",
      "[ 0.29741379  0.20239028  0.2447318   0.30972906]\n",
      "[ 0.28210536  0.19197289  0.23213501  0.29378674]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.25        0.47727273  0.25      ]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.78571429  0.07142857  0.07142857]]\n",
      "[ 0.35344828  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.29741379  0.20239028  0.2447318   0.30972906]\n",
      "p_z after abs\n",
      "[ 0.29741379  0.20239028  0.2447318   0.30972906]\n",
      "[ 0.28210536  0.19197289  0.23213501  0.29378674]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.171875    0.328125  ]\n",
      " [ 0.07142857  0.07142857  0.07142857]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "p_z after abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "[ 0.40278043  0.22658113  0.30402219  0.06661625]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.171875    0.328125  ]\n",
      " [ 0.07142857  0.07142857  0.07142857]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "p_z after abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "[ 0.40278043  0.22658113  0.30402219  0.06661625]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.171875    0.328125  ]\n",
      " [ 0.07142857  0.07142857  0.07142857]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "p_z after abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "[ 0.40278043  0.22658113  0.30402219  0.06661625]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.02941176  0.61764706  0.32352941]\n",
      " [ 0.328125    0.171875    0.328125  ]\n",
      " [ 0.07142857  0.07142857  0.07142857]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "p_z after abs\n",
      "[ 0.27178472  0.15289047  0.20514547  0.04495074]\n",
      "[ 0.40278043  0.22658113  0.30402219  0.06661625]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02272727  0.25        0.47727273]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "p_z after abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "[ 0.1548473   0.16023029  0.20177073  0.48315168]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02272727  0.25        0.47727273]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "p_z after abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "[ 0.1548473   0.16023029  0.20177073  0.48315168]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02272727  0.25        0.47727273]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "p_z after abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "[ 0.1548473   0.16023029  0.20177073  0.48315168]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02272727  0.25        0.47727273]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "p_z after abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "[ 0.1548473   0.16023029  0.20177073  0.48315168]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02272727  0.25        0.47727273]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.07142857  0.78571429  0.07142857]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "p_z after abs\n",
      "[ 0.09334591  0.09659091  0.12163254  0.29125616]\n",
      "[ 0.1548473   0.16023029  0.20177073  0.48315168]\n",
      "0\n",
      "-181.738623286\n",
      "[[ 0.2037037   0.2037037   0.57407407]\n",
      " [ 0.25        0.47727273  0.25      ]\n",
      " [ 0.171875    0.171875    0.328125  ]\n",
      " [ 0.45833333  0.04166667  0.45833333]]\n",
      "[ 0.01315789  0.53947368  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.27119883  0.3298445   0.18564967  0.15515351]\n",
      "p_z after abs\n",
      "[ 0.27119883  0.3298445   0.18564967  0.15515351]\n",
      "[ 0.28794377  0.35021046  0.19711245  0.16473333]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02272727  0.25        0.25      ]\n",
      " [ 0.38888889  0.2037037   0.38888889]\n",
      " [ 0.04166667  0.45833333  0.45833333]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "[ 0.29713699  0.13965059  0.30718633  0.25602609]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02272727  0.25        0.25      ]\n",
      " [ 0.38888889  0.2037037   0.38888889]\n",
      " [ 0.04166667  0.45833333  0.45833333]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "[ 0.29713699  0.13965059  0.30718633  0.25602609]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02272727  0.25        0.25      ]\n",
      " [ 0.38888889  0.2037037   0.38888889]\n",
      " [ 0.04166667  0.45833333  0.45833333]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "[ 0.29713699  0.13965059  0.30718633  0.25602609]\n",
      "[[ 0.171875    0.171875    0.484375  ]\n",
      " [ 0.02272727  0.25        0.25      ]\n",
      " [ 0.38888889  0.2037037   0.38888889]\n",
      " [ 0.04166667  0.45833333  0.45833333]]\n",
      "[ 0.14473684  0.01315789  0.27631579]\n",
      "p_z before abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "p_z after abs\n",
      "[ 0.16097862  0.07565789  0.166423    0.13870614]\n",
      "[ 0.29713699  0.13965059  0.30718633  0.25602609]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.04166667  0.45833333  0.04166667]]\n",
      "[ 0.14473684  0.01315789  0.53947368]\n",
      "p_z before abs\n",
      "[ 0.1198602   0.34171827  0.14247533  0.03453947]\n",
      "p_z after abs\n",
      "[ 0.1198602   0.34171827  0.14247533  0.03453947]\n",
      "[ 0.18769411  0.53511098  0.2231081   0.05408681]\n",
      "[[ 0.171875    0.171875    0.171875  ]\n",
      " [ 0.02941176  0.32352941  0.61764706]\n",
      " [ 0.328125    0.171875    0.171875  ]\n",
      " [ 0.04166667  0.45833333  0.04166667]]\n",
      "[ 0.14473684  0.01315789  0.53947368]\n",
      "p_z before abs\n",
      "[ 0.1198602   0.34171827  0.14247533  0.03453947]\n",
      "p_z after abs\n",
      "[ 0.1198602   0.34171827  0.14247533  0.03453947]\n",
      "[ 0.18769411  0.53511098  0.2231081   0.05408681]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.32352941  0.61764706  0.02941176]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.45833333  0.04166667  0.45833333]]\n",
      "[ 0.35344828  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.29741379  0.13260649  0.2447318   0.36386494]\n",
      "p_z after abs\n",
      "[ 0.29741379  0.13260649  0.2447318   0.36386494]\n",
      "[ 0.28635559  0.12767602  0.23563238  0.35033601]\n",
      "[[ 0.14864865  0.14864865  0.55405405]\n",
      " [ 0.32352941  0.61764706  0.02941176]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.45833333  0.04166667  0.45833333]]\n",
      "[ 0.35344828  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.29741379  0.13260649  0.2447318   0.36386494]\n",
      "p_z after abs\n",
      "[ 0.29741379  0.13260649  0.2447318   0.36386494]\n",
      "[ 0.28635559  0.12767602  0.23563238  0.35033601]\n",
      "[[ 0.25        0.13095238  0.48809524]\n",
      " [ 0.04166667  0.875       0.04166667]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.04166667  0.04166667  0.45833333]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "p_z after abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "[ 0.36582325  0.0468248   0.29381583  0.29353612]\n",
      "[[ 0.25        0.13095238  0.48809524]\n",
      " [ 0.04166667  0.875       0.04166667]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.04166667  0.04166667  0.45833333]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "p_z after abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "[ 0.36582325  0.0468248   0.29381583  0.29353612]\n",
      "[[ 0.25        0.13095238  0.48809524]\n",
      " [ 0.04166667  0.875       0.04166667]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.04166667  0.04166667  0.45833333]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "p_z after abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "[ 0.36582325  0.0468248   0.29381583  0.29353612]\n",
      "[[ 0.25        0.13095238  0.48809524]\n",
      " [ 0.04166667  0.875       0.04166667]\n",
      " [ 0.2037037   0.2037037   0.38888889]\n",
      " [ 0.04166667  0.04166667  0.45833333]]\n",
      "[ 0.18103448  0.00862069  0.43965517]\n",
      "p_z before abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "p_z after abs\n",
      "[ 0.26098112  0.03340517  0.20961047  0.20941092]\n",
      "[ 0.36582325  0.0468248   0.29381583  0.29353612]\n",
      "[[ 0.25        0.13095238  0.13095238]\n",
      " [ 0.04166667  0.04166667  0.875     ]\n",
      " [ 0.2037037   0.2037037   0.2037037 ]\n",
      " [ 0.04166667  0.875       0.04166667]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "p_z after abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "[ 0.16840731  0.05417755  0.20104439  0.57637076]\n",
      "[[ 0.25        0.13095238  0.13095238]\n",
      " [ 0.04166667  0.04166667  0.875     ]\n",
      " [ 0.2037037   0.2037037   0.2037037 ]\n",
      " [ 0.04166667  0.875       0.04166667]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "p_z after abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "[ 0.16840731  0.05417755  0.20104439  0.57637076]\n",
      "[[ 0.25        0.13095238  0.13095238]\n",
      " [ 0.04166667  0.04166667  0.875     ]\n",
      " [ 0.2037037   0.2037037   0.2037037 ]\n",
      " [ 0.04166667  0.875       0.04166667]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "p_z after abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "[ 0.16840731  0.05417755  0.20104439  0.57637076]\n",
      "[[ 0.25        0.13095238  0.13095238]\n",
      " [ 0.04166667  0.04166667  0.875     ]\n",
      " [ 0.2037037   0.2037037   0.2037037 ]\n",
      " [ 0.04166667  0.875       0.04166667]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "p_z after abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "[ 0.16840731  0.05417755  0.20104439  0.57637076]\n",
      "[[ 0.25        0.13095238  0.13095238]\n",
      " [ 0.04166667  0.04166667  0.875     ]\n",
      " [ 0.2037037   0.2037037   0.2037037 ]\n",
      " [ 0.04166667  0.875       0.04166667]]\n",
      "[ 0.18103448  0.35344828  0.00862069]\n",
      "p_z before abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "p_z after abs\n",
      "[ 0.09267241  0.02981322  0.11063218  0.31716954]\n",
      "[ 0.16840731  0.05417755  0.20104439  0.57637076]\n",
      "1\n",
      "-176.072901686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:228: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:230: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:231: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([[ 0.61764706,  0.25      ,  0.25      ,  0.55405405],\n",
       "         [ 0.02941176,  0.02272727,  0.47727273,  0.01351351],\n",
       "         [ 0.32352941,  0.25      ,  0.25      ,  0.41891892],\n",
       "         [ 0.02941176,  0.47727273,  0.02272727,  0.01351351]]),\n",
       "  array([[ 0.5       ,  0.95454545,  0.17741935,  0.04545455],\n",
       "         [ 0.5       ,  0.04545455,  0.82258065,  0.95454545]])),\n",
       " [-181.7386232856424, -176.07290168578751])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.update( maxiter =1, burnin = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"matrix\"\n",
    "print sampler.matrix.shape\n",
    "print \"topics\"\n",
    "print sampler.topics.shape\n",
    "print \"NZ\"\n",
    "print sampler.NZ.shape\n",
    "print \"NM\"\n",
    "print sampler.NM.shape\n",
    "print \"NZM\"\n",
    "print sampler.NZM.shape\n",
    "print \"NZW\"\n",
    "print sampler.NZW.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gibbsSampler.gibbs_sampler.gibbssampler(matrix = sampler.matrix, nzw = sampler.NZW.transpose(),\n",
    "                                                nzm = sampler.NZM.transpose(),\n",
    "                                                nz = sampler.NZ,\n",
    "                                                nm = sampler.NM,\n",
    "                                                max_iter = 10,\n",
    "                                                p_z = p_z,\n",
    "                                                m = M,\n",
    "                                                n = N,\n",
    "                                                topics = sampler.topics,\n",
    "                                                topics2 = topics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in xrange(testing_frame.shape[0]):\n",
    "    for i,w in enumerate(word_indices(testing_frame[m,:])):\n",
    "        print i,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = LdaSampler(data = train_frame.values, ntopics = 4, alpha = .1, beta = .1)\n",
    "LDAtest = sampler.runfort(maxiter = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gibbsSampler.gibbs_sampler.gibbssampler(matrix = sampler.matrix, nzw = sampler.NZW.transpose(),\n",
    "                                                nzm = sampler.NZM.transpose(),\n",
    "                                                nz = sampler.NZ,\n",
    "                                                nm = sampler.NM,\n",
    "                                                max_iter = 10,\n",
    "                                                p_z = p_z,\n",
    "                                                m = M,\n",
    "                                                n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler.NZM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
