{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "DIR = r'data_folder/wordcounts'\n",
    "allfiles = glob.glob(os.path.join(DIR,\"*.CSV\"))\n",
    "\n",
    "p = .5\n",
    "rand_sample = [ allfiles[i] for i in sorted(random.sample(xrange(len(allfiles)), int(p * len(allfiles)))) ]\n",
    "rand_sample\n",
    "    \n",
    "np_array_list = []\n",
    "for file_ in rand_sample:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    df['source'] = file_\n",
    "    np_array_list.append(df.as_matrix())\n",
    "    \n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "big_frame = pd.DataFrame(comb_np_array)\n",
    "big_frame.columns = ['words','count','source']\n",
    "\n",
    "big_frame = big_frame.pivot(index = 'source',columns = 'words', values = 'count')\n",
    "big_frame = big_frame.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>words</th>\n",
       "      <th>nan</th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaaemh</th>\n",
       "      <th>aaaai</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aac</th>\n",
       "      <th>aachen</th>\n",
       "      <th>aacm</th>\n",
       "      <th>...</th>\n",
       "      <th>zyl</th>\n",
       "      <th>zylkzkt</th>\n",
       "      <th>zymax</th>\n",
       "      <th>zymin</th>\n",
       "      <th>zyskind</th>\n",
       "      <th>zyv</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzh</th>\n",
       "      <th>zzthi</th>\n",
       "      <th>zzzt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276708.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276732.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276818.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276825.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276856.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36018 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "words                                               NaN    a  aa  aaa  \\\n",
       "source                                                                  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0    0   0    0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0    7   0    0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0   14   0    0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0   22   0    0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0  181   0    0   \n",
       "\n",
       "words                                               aaaaaaemh  aaaai  aaas  \\\n",
       "source                                                                       \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...          0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...          0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...          0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...          0      0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...          0      0     0   \n",
       "\n",
       "words                                               aac  aachen  aacm  ...   \\\n",
       "source                                                                 ...    \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0       0     0  ...    \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0       0     0  ...    \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0       0     0  ...    \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0       0     0  ...    \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0       0     0  ...    \n",
       "\n",
       "words                                               zyl  zylkzkt  zymax  \\\n",
       "source                                                                    \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0        0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0        0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0        0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0        0      0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0        0      0   \n",
       "\n",
       "words                                               zymin  zyskind  zyv  zz  \\\n",
       "source                                                                        \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...      0        0    0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...      0        0    0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...      0        0    0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...      0        0    0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...      0        0    0   0   \n",
       "\n",
       "words                                               zzh  zzthi  zzzt  \n",
       "source                                                                \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0      0     0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0      0     0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0     0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0     0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0     0  \n",
       "\n",
       "[5 rows x 36018 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some nonsense words in here, can we use some sort of dictionary to sweep them out?\n",
    "''' \n",
    "My best guess as to why this is happening is:\n",
    "1. As JSTOR parses the data things like equations and tables become jibberish.\n",
    "2. Maybe we are using the wrong character format? Maybe it's unicode?\n",
    "3. Aliens\n",
    "'''\n",
    "big_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>words</th>\n",
       "      <th>nan</th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aacm</th>\n",
       "      <th>aam</th>\n",
       "      <th>aamse</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurnal</th>\n",
       "      <th>zv</th>\n",
       "      <th>zvi</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zy</th>\n",
       "      <th>zygmund</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276708.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276732.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276818.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276825.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_folder/wordcounts/wordcounts_10.2307_2276856.CSV</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15070 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "words                                               NaN    a  aa  aac  aacm  \\\n",
       "source                                                                        \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0    0   0    0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0    7   0    0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0   14   0    0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0   22   0    0     0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0  181   0    0     0   \n",
       "\n",
       "words                                               aam  aamse  aaron  ab  \\\n",
       "source                                                                      \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0      0      0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...    0      0      0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0      0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0      0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...    0      0      0   0   \n",
       "\n",
       "words                                               abandon ...  zur  zurich  \\\n",
       "source                                                      ...                \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...        0 ...    0       0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...        0 ...    0       0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0 ...    0       0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0 ...    0       0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...        0 ...    0       0   \n",
       "\n",
       "words                                               zurnal  zv  zvi  zw  zx  \\\n",
       "source                                                                        \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...       0   0    0   0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...       0   0    0   0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...       0   0    0   0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...       0   0    0   0   0   \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...       0   0    0   0   0   \n",
       "\n",
       "words                                               zy  zygmund  zz  \n",
       "source                                                               \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...   0        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22767...   0        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0        0   0  \n",
       "data_folder/wordcounts/wordcounts_10.2307_22768...   0        0   0  \n",
       "\n",
       "[5 rows x 15070 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could do a couple of shady things like this to help remove those\n",
    "big_frame = big_frame.loc[:, (big_frame.sum(axis = 0) > 2)]\n",
    "\n",
    "big_frame.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    ''' Latent Dirichlet Allocation (LDA) \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: A D x N DataFrame holding the count of unique words in each document\n",
    "    \n",
    "    ntopics: Intiger Number of topics\n",
    "    \n",
    "    alpha: Numeric hyperparameter for Dirichlet prior for theta, the prior count of topics in a document\n",
    "    \n",
    "    beta: Numeric hyperparameter of Dirichlet prior for Phi, prior on words in a topic\n",
    "    \n",
    "    max_iter: Integer Maximum number of iterations\n",
    "    \n",
    "    burn_in: Integer burin-in iterations\n",
    "    \n",
    "    Output\n",
    "    ---------\n",
    "    Phi: An N x K Dataframe with each row being words and columns being probability of word being in topic\n",
    "    \n",
    "    Theta: A K x M Dataframe with each row being topics and columns being probability of document in topic\n",
    "    '''\n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-68ac61b30eb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mntopics\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mntopics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mNZM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNZM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mNWZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbig_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNWZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbig_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             self.obj._data = self.obj._data.setitem(indexer=indexer,\n\u001b[1;32m--> 563\u001b[1;33m                                                     value=value)\n\u001b[0m\u001b[0;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   2850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2851\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2852\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'setitem'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   2836\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2837\u001b[0m         bm = self.__class__(result_blocks, axes or self.axes,\n\u001b[1;32m-> 2838\u001b[1;33m                             do_integrity_check=do_integrity_check)\n\u001b[0m\u001b[0;32m   2839\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2840\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check, fastpath)\u001b[0m\n\u001b[0;32m   2539\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2541\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2543\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2627\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2628\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2629\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "M, N = big_frame.shape\n",
    "#998\n",
    "#M\n",
    "#166463... we're probably going to want to take a smaller sample\n",
    "#N\n",
    "\n",
    "alpha = .01\n",
    "beta = .01\n",
    "burn_in = 10\n",
    "max_iter = 100\n",
    "ntopics = 6\n",
    "NWZ = pd.DataFrame(0,index = xrange(N), columns = xrange(ntopics)) + beta\n",
    "NZM = pd.DataFrame(0, index = xrange(ntopics), columns = ['Document ' + 'i' for i in xrange(M)]) + alpha\n",
    "NZ  = NWZ.sum(axis = 0)\n",
    "Z = pd.DataFrame(0,index = xrange(M), columns = xrange(N))\n",
    "Phi = pd.DataFrame(0,index = xrange(N), columns = xrange(ntopics))\n",
    "Theta = pd.DataFrame(0,index = xrange(ntopics), columns = xrange(M))\n",
    "topicdraw = pd.DataFrame(1,index = xrange(1), columns = xrange(ntopics))/ntopics\n",
    "\n",
    "\n",
    "# Draw the initial starting points\n",
    "for m in xrange(M):\n",
    "    for n in xrange(N):\n",
    "        Z.iloc[m,n] = np.where(np.random.multinomial(1,[1./ntopics]*ntopics,size = 1 ) == 1)[1]\n",
    "        NZM.iloc[Z.iloc[m,n],m] = NZM.iloc[Z.iloc[m,n],m] + 1\n",
    "        NWZ.iloc[big_frame.iloc[m,n],Z.iloc[m,n]] = NWZ.iloc[big_frame.iloc[m,n],Z.iloc[m,n]] + 1\n",
    "        NZ.iloc[Z.iloc[m,n]] = NZ.iloc[Z.iloc[m,n]] + 1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1664.63\n",
       "1    1664.63\n",
       "2    1664.63\n",
       "3    1664.63\n",
       "4    1664.63\n",
       "5    1664.63\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = .01\n",
    "beta = .01\n",
    "burn_in = 10\n",
    "max_iter = 100\n",
    "ntopics = 6\n",
    "NWZ = pd.DataFrame(0,index = xrange(N), columns = xrange(ntopics)) + beta\n",
    "NZM = pd.DataFrame(0, index = xrange(ntopics), columns = ['Document ' + 'i' for i in xrange(M)]) + alpha\n",
    "NZ  = NWZ.sum(axis = 0)\n",
    "Z = pd.DataFrame(0,index = xrange(M), columns = xrange(N))\n",
    "Phi = pd.DataFrame(0,index = xrange(N), columns = xrange(ntopics))\n",
    "Theta = pd.DataFrame(0,index = xrange(ntopics), columns = xrange(M))\n",
    "topicdraw = pd.DataFrame(1,index = xrange(1), columns = xrange(ntopics))/ntopics\n",
    "\n",
    "NZ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
